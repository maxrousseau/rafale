run:
    name: "test-ministories" # name of your experiment, used for checkpointing
    lr: 1e-4
    n_epochs: 1
    lr_schedule: None
    seed: 42

model:
    config: "pythia14m" # config key
    type: "decoder"
    use_pretrained: True

data:
    pipeline: "tinystories_neox" # the preprocessing/tokenization pipeline
    config: "mini_tinystories" # data parameters BS, seq_len, etc.

# we want data and model configurations to be in files rather than in yaml, leave training hyperparams to yaml config only